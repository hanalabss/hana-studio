"""
core/image_processor.py ìˆ˜ì •
ë™ì  ì„ê³„ê°’ ì§€ì›
"""

import io
import numpy as np
import cv2
from PIL import Image
from rembg import remove, new_session
from config import config


class ImageProcessor:
    """ì´ë¯¸ì§€ ì²˜ë¦¬ë¥¼ ë‹´ë‹¹í•˜ëŠ” í´ë˜ìŠ¤ - ë™ì  ì„ê³„ê°’ ì§€ì›"""
    
    def __init__(self):
        self.session = None
        self._initialize_ai_model()
    
    def _initialize_ai_model(self):
        """AI ëª¨ë¸ ì´ˆê¸°í™”"""
        try:
            model_name = config.get('ai_model', 'isnet-general-use')
            print(f"AI ëª¨ë¸ ì´ˆê¸°í™” ì¤‘: {model_name}")
            self.session = new_session(model_name=model_name)
            
            model_info = config.get_ai_model_info(model_name)
            if model_info:
                print(f"âœ… {model_info['name']} ë¡œë“œ ì™„ë£Œ!")
            else:
                print("âœ… AI ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!")
                
        except Exception as e:
            print(f"âŒ AI ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            raise
    
    def is_model_ready(self) -> bool:
        """ëª¨ë¸ì´ ì¤€ë¹„ë˜ì—ˆëŠ”ì§€ í™•ì¸"""
        return self.session is not None
    
    def remove_background(self, image_path: str, alpha_threshold: int = None) -> np.ndarray:
        """
        ë°°ê²½ ì œê±° ì²˜ë¦¬ - EXIF íšŒì „ ë¬´ì‹œ (ì¸ì‡„ ê²°ê³¼ì™€ ì¼ì¹˜)
        
        Args:
            image_path: ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
            alpha_threshold: ì•ŒíŒŒ ì„ê³„ê°’ (Noneì´ë©´ configì—ì„œ ê°€ì ¸ì˜´)
        """
        if not self.session:
            raise RuntimeError("AI ëª¨ë¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        try:
            # ì„ê³„ê°’ ê²°ì •
            if alpha_threshold is None:
                alpha_threshold = config.get('alpha_threshold', 200)
            
            print(f"[DEBUG] ë°°ê²½ ì œê±° ì‹œì‘ - ì„ê³„ê°’: {alpha_threshold} (EXIF íšŒì „ ë¬´ì‹œ)")
            
            # ì´ë¯¸ì§€ íŒŒì¼ ì½ê¸°
            with open(image_path, 'rb') as f:
                input_data = f.read()
            
            # ë°°ê²½ ì œê±° ì²˜ë¦¬
            result = remove(input_data, session=self.session)
            
            # ë§ˆìŠ¤í¬ ìƒì„± (EXIF íšŒì „ ì ìš©í•˜ì§€ ì•ŠìŒ)
            img_rgba = Image.open(io.BytesIO(result)).convert("RGBA")
            alpha = np.array(img_rgba.split()[-1])
            
            print(f"[DEBUG] ì›ë³¸ ë§ˆìŠ¤í¬ í¬ê¸°: {alpha.shape} (EXIF íšŒì „ ë¬´ì‹œ)")
            
            # ì‹¤ë£¨ì—£ ë§ˆìŠ¤í¬ ìƒì„± (ë°°ê²½ì€ í°ìƒ‰, ê°ì²´ëŠ” ê²€ì€ìƒ‰)
            mask = np.where(alpha > alpha_threshold, 0, 255).astype(np.uint8)
            mask_rgb = cv2.merge([mask, mask, mask])
            
            print(f"[DEBUG] ë§ˆìŠ¤í¬ ìƒì„± ì™„ë£Œ - ì„ê³„ê°’: {alpha_threshold}, ë§ˆìŠ¤í¬ í¬ê¸°: {mask_rgb.shape}")
            
            # ë§ˆìŠ¤í¬ í†µê³„ ì¶œë ¥ (ë””ë²„ê¹…ìš©)
            black_pixels = np.sum(mask == 0)  # ê°ì²´ í”½ì…€  
            white_pixels = np.sum(mask == 255)  # ë°°ê²½ í”½ì…€
            total_pixels = mask.size
            object_ratio = (black_pixels / total_pixels) * 100
            
            print(f"[DEBUG] ë§ˆìŠ¤í¬ í†µê³„ - ê°ì²´: {object_ratio:.1f}%, ë°°ê²½: {100-object_ratio:.1f}%")
            
            # ğŸ” ìµœì¢… í™•ì¸
            height, width = mask_rgb.shape[:2]
            if height > width:
                print(f"[DEBUG] âœ… ë§ˆìŠ¤í¬: ì„¸ë¡œ í˜•íƒœ ({width}x{height}) - ì›ë³¸ê³¼ ì¼ì¹˜")
            else:
                print(f"[DEBUG] âœ… ë§ˆìŠ¤í¬: ê°€ë¡œ í˜•íƒœ ({width}x{height}) - ì›ë³¸ê³¼ ì¼ì¹˜")
            
            return mask_rgb
            
        except Exception as e:
            raise RuntimeError(f"ë°°ê²½ ì œê±° ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        
    def create_composite_preview(self, original_image: np.ndarray, mask_image: np.ndarray) -> np.ndarray:
        """í•©ì„± ë¯¸ë¦¬ë³´ê¸° ìƒì„±"""
        try:
            # ê°„ë‹¨í•œ í•©ì„± ë¯¸ë¦¬ë³´ê¸° (ì›ë³¸ + ë§ˆìŠ¤í¬ ì˜¤ë²„ë ˆì´)
            composite = original_image.copy()
            
            # ë§ˆìŠ¤í¬ë¥¼ ë°˜íˆ¬ëª…í•˜ê²Œ ì˜¤ë²„ë ˆì´
            mask_colored = cv2.applyColorMap(mask_image, cv2.COLORMAP_JET)
            composite = cv2.addWeighted(composite, 0.7, mask_colored, 0.3, 0)
            
            return composite
            
        except Exception as e:
            raise RuntimeError(f"í•©ì„± ë¯¸ë¦¬ë³´ê¸° ìƒì„± ì‹¤íŒ¨: {e}")
    
    def analyze_threshold_effectiveness(self, image_path: str, threshold_range: tuple = (50, 250), step: int = 50):
        """
        ì„ê³„ê°’ íš¨ê³¼ ë¶„ì„ (ê°œë°œ/ë””ë²„ê¹…ìš©)
        
        Args:
            image_path: ì´ë¯¸ì§€ ê²½ë¡œ
            threshold_range: í…ŒìŠ¤íŠ¸í•  ì„ê³„ê°’ ë²”ìœ„ (min, max)
            step: ì„ê³„ê°’ ì¦ê°€ ë‹¨ìœ„
            
        Returns:
            dict: ê° ì„ê³„ê°’ë³„ ê°ì²´ ë¹„ìœ¨
        """
        if not self.session:
            raise RuntimeError("AI ëª¨ë¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        try:
            # ë°°ê²½ ì œê±° í•œ ë²ˆë§Œ ìˆ˜í–‰
            with open(image_path, 'rb') as f:
                input_data = f.read()
            result = remove(input_data, session=self.session)
            img_rgba = Image.open(io.BytesIO(result)).convert("RGBA")
            alpha = np.array(img_rgba.split()[-1])
            
            # ê° ì„ê³„ê°’ë³„ ë¶„ì„
            analysis_results = {}
            min_threshold, max_threshold = threshold_range
            
            for threshold in range(min_threshold, max_threshold + 1, step):
                mask = np.where(alpha > threshold, 0, 255).astype(np.uint8)
                object_pixels = np.sum(mask == 0)
                total_pixels = mask.size
                object_ratio = (object_pixels / total_pixels) * 100
                
                analysis_results[threshold] = {
                    'object_ratio': object_ratio,
                    'background_ratio': 100 - object_ratio
                }
            
            print(f"[DEBUG] ì„ê³„ê°’ ë¶„ì„ ì™„ë£Œ: {len(analysis_results)}ê°œ ì„ê³„ê°’ í…ŒìŠ¤íŠ¸")
            return analysis_results
            
        except Exception as e:
            raise RuntimeError(f"ì„ê³„ê°’ ë¶„ì„ ì‹¤íŒ¨: {e}")
    
    def get_recommended_threshold(self, image_path: str) -> int:
        """
        ì´ë¯¸ì§€ì— ìµœì í™”ëœ ì„ê³„ê°’ ì¶”ì²œ (ì‹¤í—˜ì  ê¸°ëŠ¥)
        
        Returns:
            int: ì¶”ì²œ ì„ê³„ê°’
        """
        try:
            analysis = self.analyze_threshold_effectiveness(image_path, (100, 250), 25)
            
            # ê°ì²´ ë¹„ìœ¨ì´ 5-40% ì‚¬ì´ì¸ ì„ê³„ê°’ ì¤‘ì—ì„œ ì„ íƒ
            candidates = []
            for threshold, data in analysis.items():
                object_ratio = data['object_ratio']
                if 5 <= object_ratio <= 40:  # ì ì ˆí•œ ê°ì²´ ë¹„ìœ¨ ë²”ìœ„
                    candidates.append((threshold, object_ratio))
            
            if candidates:
                # ê°ì²´ ë¹„ìœ¨ì´ 15-25% ì‚¬ì´ì— ê°€ì¥ ê°€ê¹Œìš´ ì„ê³„ê°’ ì„ íƒ
                target_ratio = 20
                best_threshold = min(candidates, key=lambda x: abs(x[1] - target_ratio))[0]
                print(f"[DEBUG] ì¶”ì²œ ì„ê³„ê°’: {best_threshold}")
                return best_threshold
            else:
                print("[DEBUG] ì ì ˆí•œ ì„ê³„ê°’ì„ ì°¾ì§€ ëª»í•¨, ê¸°ë³¸ê°’ ì‚¬ìš©")
                return 200
                
        except Exception as e:
            print(f"[DEBUG] ì„ê³„ê°’ ì¶”ì²œ ì‹¤íŒ¨: {e}, ê¸°ë³¸ê°’ ì‚¬ìš©")
            return 200
    
    def validate_image(self, image_path: str) -> tuple[bool, str]:
        """ì´ë¯¸ì§€ íŒŒì¼ ìœ íš¨ì„± ê²€ì‚¬"""
        try:
            # ì§€ì›ë˜ëŠ” í˜•ì‹ì¸ì§€ í™•ì¸
            if not config.is_supported_image(image_path):
                return False, "ì§€ì›í•˜ì§€ ì•ŠëŠ” ì´ë¯¸ì§€ í˜•ì‹ì…ë‹ˆë‹¤."
            
            # íŒŒì¼ í¬ê¸° í™•ì¸
            import os
            max_size_mb = 50
            file_size_mb = os.path.getsize(image_path) / (1024 * 1024)
            if file_size_mb > max_size_mb:
                return False, f"íŒŒì¼ í¬ê¸°ê°€ ë„ˆë¬´ í½ë‹ˆë‹¤. (ìµœëŒ€ {max_size_mb}MB)"
            
            return True, ""
            
        except Exception as e:
            return False, f"íŒŒì¼ ê²€ì‚¬ ì¤‘ ì˜¤ë¥˜: {e}"